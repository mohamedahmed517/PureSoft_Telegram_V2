"""
Gemini AI chat service
"""
import io
import time
import base64
from PIL import Image
from datetime import datetime
from google.genai import types
from utils.logger import logger
from utils.metrics import metrics
from web_database import save_web_conversation
from services.products import build_product_catalog
from models import CLIENT, GENERATION_CONFIG, SAFETY_SETTINGS
from services.history import conversation_history, get_conversation_context, add_message

def gemini_chat(text="", image_b64=None, audio_data=None, user_key="unknown"):
    """Main chat function with Gemini AI"""
    start_time = time.time()
    max_retries = 2
    try:
        now = datetime.now().strftime("%Y-%m-%d %H:%M")
        history_text, recent_messages = get_conversation_context(user_key)
        products_text = build_product_catalog()
        prompt = f"""
ุฃูุช ุงูุจูุช ุงูุฐูู ุจุชุงุน ุขูุงู ุณุชูุฑุฒุ ุจุชุชููู ุนุงููุฉ ูุตุฑูุฉ ูุฏูุฏุฉ ูุทุจูุนูุฉ.
ุฃูุช ูุณุงุนุฏ ุดุงูู ุจุชุนุฑู ุชุชููู ูู ุฃู ููุถูุน: ููุถุฉุ ุณูุงุญุฉุ ุทูุณุ ุฃูุงูู ุฎุฑูุฌุ ูุตุงูุญ ุนุงูุฉุ ูุฃู ุญุงุฌุฉ ุชุงููุฉ.
ุขุฎุฑ ูุญุงุฏุซุฉ:
{history_text}
ุฏูู ูู ุงูููุชุฌุงุช ุงููู ููุฌูุฏุฉ ุนูุฏูุง ุฏูููุชู (ุฎุฏ ุจุงูู ูู ุงูุฃุณูุงุก ุฏู ุจุงูุญุฑู ูุฃู ุงูููููุงุช ูุฑุจูุทุฉ ุจููุง):
{products_text}
ุขุฎุฑ ุฑุณุงูู ุงููุญุงุฏุซุฉ:
{recent_messages}
ุงูุนููู ุจูููู ุฏูููุชู: {text or "ุจุนุช ุตูุฑุฉ" if not audio_data else "ุจุนุช ุตูุช"}
ููุงุนุฏ ุงูุฑุฏ:
1. ูู ุงูุนููู ุณุฃูู ุนู ุญุงุฌุฉ ุนุงูุฉ (ุณูุงุญุฉุ ุทูุณุ ุฃูุงููุ ูุตุงูุญุ ุฃู ููุถูุน) โ ุฑุฏ ุนููู ุนุงุฏู ูุทุจูุนู ูู ุบูุฑ ูุง ุชุฑุดุญ ููุชุฌุงุช ุฅูุง ูู ูู ุทูุจ ูุฏู ุจูุถูุญ
2. ูู ุณุฃู ุนู ุงูุทูุณ ูู ููุงู ูุนูู โ ูููู ุงูุทูุณ ุฅูู ููููู ุชูุตุญู ุจุงููุจุณ ุงูููุงุณุจ ููุฌู ุฏู (ุจุณ ูุชุฑุดุญุด ููุชุฌุงุช ุฅูุง ูู ูู ุทูุจ)
3. ูู ุณุฃู ุนู ุฃูุงูู ุฎุฑูุฌ ุฃู ูุณุญ โ ุฑุดุญูู ุฃูุงูู ุญููุฉ ูุงุฏููู ูุนูููุงุช ูููุฏุฉ
4. ูู ูุงูู "ูุชุฑุดุญููุด ููุชุฌุงุช ุฏูููุชู" ุฃู "ูุด ุนุงูุฒ ุฃุดูู ููุชุฌุงุช" โ ูุชุฑุดุญุด ุฎุงูุต ูุงุชููู ุนุงุฏู
5. ูู ุทูุจ ููู ุตุฑุงุญุฉ ูุดูู ูุจุณ ุฃู ููุชุฌุงุช ุฃู ุจุนุช ุตูุฑุฉ ูุจุณ/ููุชุฌ ุนุดุงู ูุนุฑู ุดุจูู ุฅูู:
   - ุฑุดุญูู ูู ุงูููุชุฌุงุช ุงููู ููู ุจุงูุดูู ุฏู ุจุงูุธุจุท (ุณุทุฑ ููุงุณูุ ุณุทุฑ ููุณุนุฑุ ุณุทุฑ ูููุงุชูุฌูุฑูุ ุณุทุฑ ููููู):
  
   ุชูุดูุฑุช ูุทู ุณุงุฏุฉ ุงุจูุถ
   ุงูุณุนุฑ: 130 ุฌููู
   ุงููุงุชูุฌูุฑู: ูุจุณ ุตููู
   ุงููููู: https://afaq-stores.com/product-details/1019
  
   ุณูุงุฑู ูุดููุฑ ุทููู
   ุงูุณุนุฑ: 290 ุฌููู
   ุงููุงุชูุฌูุฑู: ูุจุณ ุฎุฑููู
   ุงููููู: https://afaq-stores.com/product-details/1014
  
   ุฌุงููุช ุฌูุฏ ุงุณูุฏ ุชููู ูุจุทู ูุฑู
   ุงูุณุนุฑ: 720 ุฌููู
   ุงููุงุชูุฌูุฑู: ูุจุณ ุดุชูู
   ุงููููู: https://afaq-stores.com/product-details/1001
6. ููู ุฌุฏูุง: ุงุณุชุฎุฏู ุฃุณูุงุก ุงูููุชุฌุงุช ุฒู ูุง ูู ููุชูุจุฉ ููู ูู ุบูุฑ ูุง ุชูุตุฑูุง ุฃู ุชุบูุฑ ูููุง ููุง ุญุฑู
7. ูู ุจุนุช ุตูุฑุฉ ูุจุณ/ููุชุฌ โ ุงุจุฏุฃ ุงูุฑุฏ ุจู "ุซุงููุฉ ุจุณ ุฃุดูู ุงูุตูุฑุฉ..."
8. ูู ุจุนุช ุตูุฑุฉ ุนุงุฏูุฉ (ูุด ูุจุณ) โ ุญูู ุงูุตูุฑุฉ ูุฑุฏ ุนููู ุนุงุฏู ูู ุบูุฑ ูุง ุชุฑุดุญ ููุชุฌุงุช
9. ูู ุจุนุช ุตูุช โ ุงุณูุน ุงูุตูุช ูููุณ ูุฑุฏ ุนูู ุงููู ุจููููู
ุฃุณููุจ ุงูููุงู:
- ุงุชููู ุนุงููุฉ ูุตุฑูุฉ 100% ูุจุดูู ุทุจูุนู ููุฑูุญ
- ูุชุญุทุด ุฅูููุฌู ุฎุงูุต
- ูุชูููุด ุฅูู ุจูุช ุฃุจุฏูุง
- ูู ูููุฏ ููุฏูุฏ ูู ุฃู ููุถูุน
- ูู ูุด ุนุงุฑู ุญุงุฌุฉุ ุงุนุชุฑู ุจูุฏู ุจุดูู ุทุจูุนู
ุฑุฏ ุฏูููุชู:
""".strip()
        response = None
        for attempt in range(max_retries):
            try:
                config_dict = GENERATION_CONFIG.model_dump() if hasattr(GENERATION_CONFIG, 'model_dump') else GENERATION_CONFIG.dict()
                config_dict.pop('safety_settings', None)
                
                if audio_data:
                    response = CLIENT.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=[
                            prompt,
                            {"mime_type": "audio/ogg", "data": audio_data}
                        ],
                        config=types.GenerateContentConfig(
                            **config_dict,
                            safety_settings=SAFETY_SETTINGS
                        )
                    )
                    metrics.track_message("with_audio")
                   
                elif image_b64:
                    img = Image.open(io.BytesIO(base64.b64decode(image_b64)))
                    img_bytes = io.BytesIO()
                    img.save(img_bytes, format='PNG')
                    img_bytes.seek(0)
                   
                    response = CLIENT.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=[
                            prompt,
                            {"mime_type": "image/png", "data": img_bytes.read()}
                        ],
                        config=types.GenerateContentConfig(
                            **config_dict,
                            safety_settings=SAFETY_SETTINGS
                        )
                    )
                    metrics.track_message("with_image")
                   
                else:
                    response = CLIENT.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=prompt,
                        config=types.GenerateContentConfig(
                            **config_dict,
                            safety_settings=SAFETY_SETTINGS
                        )
                    )
                    metrics.track_message("text_only")
                   
                break
               
            except Exception as e:
                logger.warning(f"โ๏ธ Gemini API attempt {attempt + 1}/{max_retries} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(1)
                else:
                    raise
       
        reply = response.text.strip() if response and hasattr(response, "text") and response.text else "ุซูุงูู ุจุณ ููู ูุดููุฉ ุฏูููุชู..."
        
        add_message(user_key, "user", text or ("[ุตูุฑุฉ]" if image_b64 else "[ุตูุช]"), now)
        add_message(user_key, "assistant", reply, now)
        
        if user_key.startswith("web:"):
            try:
                user_id = int(user_key.split(":")[1])
                history = conversation_history.get(user_key, [])
                save_web_conversation(user_id, history)
                logger.info(f"๐พ Saved web conversation for user {user_id}")
            except Exception as e:
                logger.error(f"โ Error saving web conversation: {e}")
        
        response_time = time.time() - start_time
        metrics.track_response_time(response_time)
       
        logger.info(f"โ Response generated for {user_key} in {response_time:.2f}s")
        return reply
    except Exception as e:
        logger.error(f"โ Error in gemini_chat: {e}", exc_info=True)
        metrics.track_error("gemini_chat")
        return "ุซูุงูู ุจุณ ููู ูุดููุฉ ุฏูููุชู ูุญููุง ูุงุฑุฌุนูู..."
